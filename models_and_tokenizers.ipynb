{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBFVDMzY4catn1TNuPRegq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bieguni101/hugging-face-nlp-cource/blob/main/models_and_tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbcSyqkkqF9N"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
        "print(type(bert_model))\n",
        "\n",
        "gpt_model = AutoModel.from_pretrained(\"gpt2\")\n",
        "print(type(gpt_model))\n",
        "\n",
        "bart_model = AutoModel.from_pretrained(\"facebook/bart-base\")\n",
        "print(type(bart_model))"
      ],
      "metadata": {
        "id": "geRudNIuqMAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "bert_config = AutoConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(bert_config)\n",
        "\n",
        "gpt_config = AutoConfig.from_pretrained(\"gpt2\")\n",
        "print(gpt_config)\n",
        "\n",
        "bart_config = AutoConfig.from_pretrained(\"facebook/bart-base\")\n",
        "print(bart_config)"
      ],
      "metadata": {
        "id": "I70s4gGatvM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
        "print(bert_config)"
      ],
      "metadata": {
        "id": "R2HVe_m-ujl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Config\n",
        "gpt_config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "print(gpt_config)"
      ],
      "metadata": {
        "id": "5AxoVU3Zuvwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartConfig\n",
        "bart_config = BartConfig.from_pretrained(\"facebook/bart-base\")\n",
        "print(bart_config)"
      ],
      "metadata": {
        "id": "nu4XG8zXuxAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "bert_config = BertConfig.from_pretrained(\"bert-base-cased\", num_hidden_layers=10)\n",
        "bert_model = BertModel(bert_config)\n",
        "\n",
        "bert_model.save_pretrained(\"my-bert-model\")"
      ],
      "metadata": {
        "id": "wXRZy_RQvRqZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, AutoConfig\n",
        "\n",
        "my_bert_model = BertModel.from_pretrained(\"my-bert-model\")\n",
        "my_bert_config = AutoConfig.from_pretrained(\"my-bert-model\")\n",
        "print(my_bert_config)"
      ],
      "metadata": {
        "id": "Rrrt-hMuwClv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "sequence = \"Using a Transformer network is simple\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)\n",
        "\n",
        "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "print(decoded_string)"
      ],
      "metadata": {
        "id": "L-vYlprOj50g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "sequence = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "input_ids = torch.tensor([ids])\n",
        "print(\"Input IDs:\", input_ids)\n",
        "\n",
        "output = model(input_ids)\n",
        "print(\"Logits:\", output.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eICyCHSpoA46",
        "outputId": "e223a744-481f-4bd0-a8a0-70a26d9de6fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,\n",
            "          2026,  2878,  2166,  1012]])\n",
            "Logits: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# id: [[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]]\n",
        "sequence1 = \"I've been waiting for a HuggingFace course my whole life.\"\n",
        "# id: [[7993, 170, 11303, 1200, 2443, 1110, 3014]]\n",
        "sequence2 = \"Using a Transformer network is simple\"\n",
        "\n",
        "tokens1 = tokenizer.tokenize(sequence1)\n",
        "ids1 = tokenizer.convert_tokens_to_ids(tokens1)\n",
        "input_ids1 = torch.tensor([ids1])\n",
        "\n",
        "tokens2 = tokenizer.tokenize(sequence2)\n",
        "ids2 = tokenizer.convert_tokens_to_ids(tokens2)\n",
        "input_ids2 = torch.tensor([ids2])\n",
        "\n",
        "all_ids = torch.tensor(\n",
        "    [[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012],\n",
        "     [7993, 170, 11303, 1200, 2443, 1110, 3014, 0, 0, 0, 0, 0, 0, 0]]\n",
        ")\n",
        "\n",
        "print(\"Logits1:\", model(input_ids1).logits)\n",
        "print(\"Logits2:\", model(input_ids2).logits)\n",
        "print(\"LogitsAll:\", model(all_ids).logits)\n",
        "\n",
        "batched_ids = [\n",
        "    [200, 200, 200],\n",
        "    [200, 200, tokenizer.pad_token_id],\n",
        "]\n",
        "\n",
        "attention_mask = [\n",
        "    [1, 1, 1],\n",
        "    [1, 1, 0],\n",
        "]\n",
        "\n",
        "outputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\n",
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigQ76kUqdEI",
        "outputId": "7b89788f-31bf-4347-923b-074afd7c837c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits1: tensor([[-2.7276,  2.8789]], grad_fn=<AddmmBackward0>)\n",
            "Logits2: tensor([[ 2.5189, -2.1906]], grad_fn=<AddmmBackward0>)\n",
            "LogitsAll: tensor([[-2.7276,  2.8789],\n",
            "        [ 1.6226, -1.4600]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 1.5694, -1.3895],\n",
            "        [ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "sequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
        "\n",
        "# Returns PyTorch tensors\n",
        "model_inputs1 = tokenizer(sequences, padding=True, return_tensors=\"pt\")\n",
        "print(\"PyTorch:\", model_inputs1)\n",
        "# 包含了开头和结尾的特殊词\n",
        "print(\"input_ids\", model_inputs1[\"input_ids\"])\n",
        "\n",
        "tokens = tokenizer.tokenize(sequences)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(\"ids:\", ids)\n",
        "\n",
        "# Returns TensorFlow tensors\n",
        "model_inputs2 = tokenizer(sequences, padding=True, return_tensors=\"tf\")\n",
        "print(\"TensorFlow:\", model_inputs2)\n",
        "\n",
        "# Returns NumPy arrays\n",
        "model_inputs3 = tokenizer(sequences, padding=True, return_tensors=\"np\")\n",
        "print(\"NumPy:\", model_inputs3)"
      ],
      "metadata": {
        "id": "-cYK5bV-vDww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}